{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad39087e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 11:34:07.419937: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re           \n",
    "# from attention import AttentionLayer\n",
    "# from tensorflow.keras.layers import Attention\n",
    "from bs4 import BeautifulSoup \n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords   \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a025714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "logger = tf.get_logger()\n",
    "\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "\n",
    "        logger.debug(f\"encoder_out_seq.shape = {encoder_out_seq.shape}\")\n",
    "        logger.debug(f\"decoder_out_seq.shape = {decoder_out_seq.shape}\")\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            logger.debug(\"Running energy computation step\")\n",
    "\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                raise TypeError(f\"States must be an iterable. Got {states} of type {type(states)}\")\n",
    "\n",
    "            encoder_full_seq = states[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_full_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "\n",
    "            logger.debug(f\"U_a_dot_h.shape = {U_a_dot_h.shape}\")\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "\n",
    "            logger.debug(f\"Ws_plus_Uh.shape = {Ws_plus_Uh.shape}\")\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            logger.debug(f\"ei.shape = {e_i.shape}\")\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            logger.debug(\"Running attention vector computation step\")\n",
    "\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                raise TypeError(f\"States must be an iterable. Got {states} of type {type(states)}\")\n",
    "\n",
    "            encoder_full_seq = states[-1]\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_full_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "\n",
    "            logger.debug(f\"ci.shape = {c_i.shape}\")\n",
    "\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        # we don't maintain states between steps when computing attention\n",
    "        # attention is stateless, so we're passing a fake state for RNN step function\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e], constants=[encoder_out_seq]\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c], constants=[encoder_out_seq]\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b130318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfac7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('text_summarization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47fed71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79192</th>\n",
       "      <td>durporobash</td>\n",
       "      <td>রিপাবলিকান পার্টির সিটি সার্জেন্ট অ্যাট আর্মস পদে বাংলাদেশি</td>\n",
       "      <td>যুক্তরাষ্ট্রের নিউজার্সি অঙ্গরাজ্যের ব্রিগেনটিন সিটিতে সম্প্রতি অনুষ্ঠিত রিপাবলিকান পার্টির নির্বাচনে বাংলাদেশি বংশোদ্ভূত রেজাউল ইসলাম খালিদ আগামী দুই বছরের জন্য পার্টির সার্জেন্ট অ্যাট আর্মস পদে ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>bangladesh</td>\n",
       "      <td>নূর হোসেনের বিরুদ্ধে আজও অভিযোগ গঠন হয়নি</td>\n",
       "      <td>নারায়ণগঞ্জের সাত খুনের মামলার প্রধান আসামি ও তাঁর দুই সহযোগীর বিরুদ্ধে ভারতের পশ্চিমবঙ্গের একটি আদালতে আজ সোমবার দ্বিতীয় দফায় অভিযোগ গঠনের তারিখ ধার্য ছিল। তবে আজও তাঁদের বিরুদ্ধে অভিযোগ গঠন হয...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28638</th>\n",
       "      <td>bangladesh</td>\n",
       "      <td>পঞ্চগড়ে তিন দিনব্যাপী ধামের গান উৎসব শেষ</td>\n",
       "      <td>পঞ্চগড়ের বোদায় গতকাল শনিবার সন্ধ্যায় শেষ হয়েছে বিলুপ্তপ্রায় ধামের গান উৎসব। গত বৃহস্পতিবার উপজেলা প্রশাসন ও হাঙ্গার ফ্রি ওয়ার্ল্ড যৌথভাবে এই উৎসবের আয়োজন করে।বৃহস্পতিবার উপজেলা পরিষদ মিলনায়তনে ‘লো...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45896</th>\n",
       "      <td>bangladesh</td>\n",
       "      <td>রাজৈরে দুই গ্রামবাসীর সংঘর্ষে আহত ৫০, মহাসড়ক অবরোধ</td>\n",
       "      <td>জুয়া খেলার প্রতিবাদ করার সূত্র ধরে মাদারীপুরের রাজৈর উপজেলার টেকেরহাট এলাকায় গতকাল বুধবার দুটি গ্রামের বাসিন্দাদের মধ্যে সংঘর্ষে অন্তত ৫০ জন আহত হয়েছেন। আহত ব্যক্তিদের রাজৈর, মাদারীপুর ও ফরিদপুরে ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          category  \\\n",
       "79192  durporobash   \n",
       "2411    bangladesh   \n",
       "28638   bangladesh   \n",
       "45896   bangladesh   \n",
       "\n",
       "                                                           summary  \\\n",
       "79192  রিপাবলিকান পার্টির সিটি সার্জেন্ট অ্যাট আর্মস পদে বাংলাদেশি   \n",
       "2411                     নূর হোসেনের বিরুদ্ধে আজও অভিযোগ গঠন হয়নি   \n",
       "28638                    পঞ্চগড়ে তিন দিনব্যাপী ধামের গান উৎসব শেষ   \n",
       "45896           রাজৈরে দুই গ্রামবাসীর সংঘর্ষে আহত ৫০, মহাসড়ক অবরোধ   \n",
       "\n",
       "                                                                                                                                                                                                          text  \n",
       "79192  যুক্তরাষ্ট্রের নিউজার্সি অঙ্গরাজ্যের ব্রিগেনটিন সিটিতে সম্প্রতি অনুষ্ঠিত রিপাবলিকান পার্টির নির্বাচনে বাংলাদেশি বংশোদ্ভূত রেজাউল ইসলাম খালিদ আগামী দুই বছরের জন্য পার্টির সার্জেন্ট অ্যাট আর্মস পদে ...  \n",
       "2411   নারায়ণগঞ্জের সাত খুনের মামলার প্রধান আসামি ও তাঁর দুই সহযোগীর বিরুদ্ধে ভারতের পশ্চিমবঙ্গের একটি আদালতে আজ সোমবার দ্বিতীয় দফায় অভিযোগ গঠনের তারিখ ধার্য ছিল। তবে আজও তাঁদের বিরুদ্ধে অভিযোগ গঠন হয...  \n",
       "28638  পঞ্চগড়ের বোদায় গতকাল শনিবার সন্ধ্যায় শেষ হয়েছে বিলুপ্তপ্রায় ধামের গান উৎসব। গত বৃহস্পতিবার উপজেলা প্রশাসন ও হাঙ্গার ফ্রি ওয়ার্ল্ড যৌথভাবে এই উৎসবের আয়োজন করে।বৃহস্পতিবার উপজেলা পরিষদ মিলনায়তনে ‘লো...  \n",
       "45896  জুয়া খেলার প্রতিবাদ করার সূত্র ধরে মাদারীপুরের রাজৈর উপজেলার টেকেরহাট এলাকায় গতকাল বুধবার দুটি গ্রামের বাসিন্দাদের মধ্যে সংঘর্ষে অন্তত ৫০ জন আহত হয়েছেন। আহত ব্যক্তিদের রাজৈর, মাদারীপুর ও ফরিদপুরে ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "865f8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['text'],inplace=True)  #dropping duplicates\n",
    "df.dropna(axis=0,inplace=True)   #dropping na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24efe1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : '_START_ '+ x + ' _END_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d07e4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text=80 \n",
    "max_len_summary=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a796c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(df['text'],df['summary'],test_size=0.1,random_state=0,shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bdfc424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33055    নিখোঁজের তিন দিন পর গতকাল মঙ্গলবার সকালে বগুড়ার আদমদীঘি উপজেলার অন্তাহার গ্রামের মাঠ থেকে জাহেদুল ইসলাম (৪২) নামের এক কৃষককে অর্ধমৃত অবস্থায় উদ্ধার করেছে গ্রামবাসী।তাঁকে নওগাঁ সদর হাসপাতালে ভর্ত...\n",
       "18972    জাতিসংঘের মহাসচিব বান কি মুন চলতি সপ্তাহে উত্তর কোরিয়া সফরে যাবেন। জাতিসংঘের একজন জ্যেষ্ঠ কর্মকর্তার বরাত দিয়ে দক্ষিণ কোরিয়ার বার্তা সংস্থা ইয়োনহ্যাপ এ কথা জানিয়েছে। তবে জাতিসংঘ এ ব্যাপারে মন...\n",
       "44647    নিউইয়র্কের লং আইল্যান্ড সিটির ফাইভ স্টার ব্যাংকুয়েট অ্যান্ড পার্টি হলে আগামী ৮ অক্টোবর অনুষ্ঠিত হবে বাংলাদেশের দরিদ্র ও মেধাবী শিক্ষার্থীদের সহায়তা প্রদানকারী আন্তর্জাতিক সেবামূলক সংগঠন দা অপটিমিস...\n",
       "60860    সদ্য অবসরে যাওয়া বিচারক মোতাহার হোসেনের বিরুদ্ধে অবৈধ সম্পদ অর্জনের অভিযোগ অনুসন্ধান শুরু করেছে দুর্নীতি দমন কমিশন (দুদক)। এ জন্য একজন কর্মকর্তাও নিয়োগ করেছে সংস্থাটি।একই সঙ্গে মোতাহার হোসেনের বিদ...\n",
       "6056     সাতক্ষীরা সদর উপজেলার তিনটি গ্রামে অজ্ঞাত রোগে গতকাল মঙ্গলবার পর্যন্ত ১০ দিনে শতাধিক ছাগল মারা গেছে। এ কারণে অনেকে কম দামে ছাগল বিক্রি করে দিতে বাধ্য হচ্ছেন।দেবনগর গ্রামের পশুচিকিৎসক মোস্তাফিজুর র...\n",
       "                                                                                                          ...                                                                                                   \n",
       "21258    তিন বছর বয়সী দুই যমজ মেয়েকে হত্যা হত্যার পর মা শারমিন বেগম (৩০) নদীতে ঝাঁপ দিয়ে আত্মহত্যার চেষ্টা করেছেন বলে অভিযোগ পাওয়া গেছে। স্থানীয়রা তাঁকে উদ্ধার করে হাসপাতালে ভর্তি করেন।বরিশালের বাবুগঞ...\n",
       "45944    সব স্তরের সাংগঠনিক শাখাগুলোর দ্রুত সম্মেলন শেষ করতে কেন্দ্রীয় নেতাদের সমন্বয়ে ১০টি টিম গঠন করেছে আওয়ামী লীগ। সংগঠনের জেলা ও উপজেলা নেতাদের এ বিষয়ে প্রয়োজনীয় উদ্যোগ নেওয়ার আহ্বান জানিয়েছে দ...\n",
       "42658    সরকার নির্ধারিত মূল্যের চেয়ে বাজারে গমের দাম কম হওয়ায় সোলার প্যানেল স্থাপন প্রকল্পের কাজে আগ্রহী হয়নি বেসরকারি উন্নয়ন সংস্থা (এনজিও) ‘এসকেএস ফাউন্ডেশন’। এ কারণে ফেরত গেছে দুর্যোগব্যবস্থাপনা ও ত্...\n",
       "43614    বাংলাদেশ আওয়ামী স্বেচ্ছাসেবক লীগের শরীয়তপুর জেলা কমিটি ঘোষণা করা হয়েছে। কেন্দ্রীয় কমিটির সাধারণ সম্পাদক পঙ্কজ নাথ গত ৩১ জুলাই ঢাকা থেকে ৫৭ সদস্যের নামের তালিকায় স্বাক্ষর করেন।সম্মেলন ছাড়া কমিটি গঠ...\n",
       "68406    দুবার পেছানোর পর কাল শনিবার পাবনার ঈশ্বরদী উপজেলা ও পৌর ছাত্রলীগের ত্রিবার্ষিক সম্মেলন অনুষ্ঠিত হতে যাচ্ছে। সম্মেলনে নতুন কমিটি গঠন করা হবে।দলীয় সূত্রে জানা গেছে, সর্বশেষ ২০১২ সালের ১৫ জানুয়ারি উপ...\n",
       "Name: text, Length: 72132, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0329d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
    "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
    "\n",
    "x_voc_size   =  len(x_tokenizer.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "492b498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing a tokenizer for summary on training data \n",
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert summary sequences into integer sequences\n",
    "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
    "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
    "\n",
    "y_voc_size  =   len(y_tokenizer.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de49666a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 11:39:40.096145: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-21 11:39:40.097069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-21 11:39:40.098110: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-21 11:39:40.394810: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-21 11:39:40.396309: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-21 11:39:40.397214: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-21 11:39:40.719624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-21 11:39:40.721037: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-21 11:39:40.722043: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-21 11:39:41.184521: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-21 11:39:41.185641: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-21 11:39:41.186523: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 80)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 80, 500)      334514000   ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 80, 500),    2002000     ['embedding[0][0]']              \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 80, 500),    2002000     ['lstm[0][0]']                   \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 500)    24278000    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 80, 500),    2002000     ['lstm_1[0][0]']                 \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 500),  2002000     ['embedding_1[0][0]',            \n",
      "                                 (None, 500),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 500)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, None, 500),  500500     ['lstm_2[0][0]',                 \n",
      " r)                              (None, None, 80))                'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 1000)   0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 48556)  48604556   ['concat_layer[0][0]']           \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 415,905,056\n",
      "Trainable params: 415,905,056\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session() \n",
    "latent_dim = 500 \n",
    "\n",
    "# Encoder \n",
    "encoder_inputs = Input(shape=(max_len_text,)) \n",
    "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
    "\n",
    "#LSTM 1 \n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "#LSTM 2 \n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "#LSTM 3 \n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "\n",
    "# Set up the decoder. \n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "#LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "#Attention Layer\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "# Concat attention output and decoder LSTM output \n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "834203a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701aab04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 11:39:53.362762: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-21 11:39:53.364465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-21 11:39:53.365587: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-21 11:39:53.555487: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-21 11:39:53.556681: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-21 11:39:53.557733: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-21 11:39:53.753820: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-21 11:39:53.755711: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-21 11:39:53.757102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-21 11:39:53.948017: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-21 11:39:53.949178: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-21 11:39:53.950487: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-21 11:39:56.044969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-21 11:39:56.046258: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-21 11:39:56.047434: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-21 11:39:56.218928: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-21 11:39:56.220099: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-21 11:39:56.221146: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-21 11:39:56.394466: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-21 11:39:56.395798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-21 11:39:56.396851: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-21 11:39:56.569041: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-21 11:39:56.570251: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-21 11:39:56.571292: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word \n",
    "reverse_source_word_index=x_tokenizer.index_word \n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e83f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder inference\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# decoder inference\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa48e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Chose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "            # Exit condition: either hit max length or find stop word.\n",
    "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13698a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if(i!=0):\n",
    "        newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03957928",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_val)):\n",
    "  print(\"Review:\",seq2text(x_val[i]))\n",
    "  print(\"Original summary:\",seq2summary(y_val[i]))\n",
    "  print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2f1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
